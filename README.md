# PGx-LLM-Eval
### Running a local llama via vLLM
```
# Starts an OAI-compatible API server on port 8000
python -m vllm.entrypoints.openai.api_server --model meta-llama/Meta-Llama-3-8B-Instruct 
```
